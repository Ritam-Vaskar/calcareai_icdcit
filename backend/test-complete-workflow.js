require('dotenv').config();
const { createClient } = require('@deepgram/sdk');
const ModelClient = require('@azure-rest/ai-inference').default;
const { isUnexpected } = require('@azure-rest/ai-inference');
const { AzureKeyCredential } = require('@azure/core-auth');
const fs = require('fs');
const path = require('path');

async function testCompleteWorkflow() {
    console.log('\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó');
    console.log('‚ïë   COMPLETE AI CONVERSATION WORKFLOW TEST              ‚ïë');
    console.log('‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n');

    // Check all required API keys
    console.log('üìã Step 1: Checking API Keys...\n');

    const checks = {
        deepgram: !!process.env.DEEPGRAM_API_KEY,
        github: !!process.env.GITHUB_TOKEN
    };

    if (checks.deepgram) {
        console.log('‚úÖ DEEPGRAM_API_KEY: Found');
    } else {
        console.log('‚ùå DEEPGRAM_API_KEY: Missing');
    }

    if (checks.github) {
        console.log('‚úÖ GITHUB_TOKEN: Found');
    } else {
        console.log('‚ùå GITHUB_TOKEN: Missing');
    }

    if (!checks.deepgram || !checks.github) {
        console.log('\n‚ùå Missing required API keys. Please check your .env file.\n');
        return;
    }

    console.log('\n' + '‚îÄ'.repeat(60) + '\n');

    // Initialize services
    const deepgram = createClient(process.env.DEEPGRAM_API_KEY);
    const aiClient = ModelClient(
        "https://models.github.ai/inference",
        new AzureKeyCredential(process.env.GITHUB_TOKEN)
    );

    // Test 1: Speech-to-Text (STT)
    console.log('üé§ Step 2: Testing Speech-to-Text (Deepgram STT)...\n');

    try {
        // Create a simple test audio buffer (silence - just for API test)
        const testAudioBuffer = Buffer.alloc(8000); // 1 second of silence

        console.log('   üìù Simulating patient speech: "I am feeling better"');
        console.log('   üîÑ Sending to Deepgram for transcription...');

        // Note: This will likely return empty since it's silence, but tests the API
        const sttResponse = await deepgram.listen.prerecorded.transcribeFile(
            testAudioBuffer,
            {
                model: 'nova-2',
                language: 'en-IN',
                smart_format: true,
                punctuate: true,
                encoding: 'mulaw',
                sample_rate: 8000,
                container: 'none'
            }
        );

        if (sttResponse.error) {
            throw sttResponse.error;
        }

        console.log('   ‚úÖ Deepgram STT API: Working');
        console.log('   ‚ÑπÔ∏è  Note: Empty transcript expected (test audio is silence)\n');
    } catch (error) {
        console.log('   ‚ùå Deepgram STT Error:', error.message);
        console.log('   ‚ö†Ô∏è  This may affect call transcription\n');
    }

    console.log('‚îÄ'.repeat(60) + '\n');

    // Test 2: AI Response Generation
    console.log('ü§ñ Step 3: Testing AI Response (GitHub Models GPT-4o-mini)...\n');

    try {
        const testTranscript = "I am feeling better after taking my medication.";
        console.log('   üìù Patient input:', testTranscript);
        console.log('   üîÑ Generating AI response...');

        const systemPrompt = `You are CareCall AI, a friendly healthcare assistant. 
The patient just said they are feeling better. Respond warmly in 1-2 sentences.`;

        const aiResponse = await aiClient.path("/chat/completions").post({
            body: {
                messages: [
                    { role: "system", content: systemPrompt },
                    { role: "user", content: testTranscript }
                ],
                model: "openai/gpt-4o-mini",
                temperature: 0.7,
                max_tokens: 100,
                top_p: 0.9
            }
        });

        if (isUnexpected(aiResponse)) {
            throw aiResponse.body.error;
        }

        const response = aiResponse.body.choices[0].message.content;
        console.log('   ‚úÖ AI Response Generated Successfully!');
        console.log('   üí¨ AI says:', response);
        console.log('');
    } catch (error) {
        console.log('   ‚ùå AI Generation Error:', error.message);
        console.log('   ‚ö†Ô∏è  This will prevent AI from responding during calls\n');
        return;
    }

    console.log('‚îÄ'.repeat(60) + '\n');

    // Test 3: Text-to-Speech (TTS)
    console.log('üîä Step 4: Testing Text-to-Speech (Deepgram TTS)...\n');

    try {
        const testText = "That's wonderful to hear! Please continue taking your medications as prescribed.";
        console.log('   üìù Text to convert:', testText);
        console.log('   üîÑ Converting to speech...');

        const ttsResponse = await deepgram.speak.request(
            { text: testText },
            {
                model: 'aura-asteria-en',
                encoding: 'mulaw',
                sample_rate: 8000,
                container: 'none'
            }
        );

        const stream = await ttsResponse.getStream();
        if (!stream) {
            throw new Error('No audio stream returned');
        }

        const chunks = [];
        const reader = stream.getReader();

        while (true) {
            const { done, value } = await reader.read();
            if (done) break;
            chunks.push(value);
        }

        const audioBuffer = Buffer.concat(chunks);

        console.log('   ‚úÖ Deepgram TTS: Working');
        console.log('   üìä Audio buffer size:', audioBuffer.length, 'bytes');
        console.log('   üìä Format: mulaw @ 8kHz (Twilio compatible)');

        // Save test audio
        const outputPath = path.join(__dirname, 'test-complete-workflow.raw');
        fs.writeFileSync(outputPath, audioBuffer);
        console.log('   üíæ Test audio saved to:', outputPath);
        console.log('');
    } catch (error) {
        console.log('   ‚ùå Deepgram TTS Error:', error.message);
        console.log('   ‚ö†Ô∏è  Patients will not hear AI responses\n');
        return;
    }

    console.log('‚îÄ'.repeat(60) + '\n');

    // Final Summary
    console.log('‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó');
    console.log('‚ïë              üéâ WORKFLOW TEST COMPLETE! üéâ             ‚ïë');
    console.log('‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n');

    console.log('‚úÖ All components are working:\n');
    console.log('   1. ‚úÖ Speech-to-Text (Deepgram STT)');
    console.log('   2. ‚úÖ AI Response (GitHub Models GPT-4o-mini)');
    console.log('   3. ‚úÖ Text-to-Speech (Deepgram TTS)\n');

    console.log('üìû Your AI follow-up calls will:');
    console.log('   ‚Ä¢ Hear patients clearly (Deepgram STT)');
    console.log('   ‚Ä¢ Generate intelligent responses (GPT-4o-mini)');
    console.log('   ‚Ä¢ Speak naturally (Deepgram TTS)\n');

    console.log('üöÄ System is ready for production calls!\n');
}

testCompleteWorkflow().catch((err) => {
    console.error("\n‚ùå Test failed with error:", err);
    console.error("\nPlease check your API keys and network connection.\n");
});
